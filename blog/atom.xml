<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://prestodb.io/blog</id>
    <title> Blog</title>
    <updated>2019-08-05T06:00:00Z</updated>
    <generator>Feed for Node.js</generator>
    <link rel="alternate" href="https://prestodb.io/blog"/>
    <subtitle>The best place to stay up-to-date with the latest  news and events.</subtitle>
    <logo>https://prestodb.io/img/presto.png</logo>
    <rights>Copyright © 2013-2019 Facebook</rights>
    <entry>
        <title type="html"><![CDATA[Presto Unlimited: MPP SQL Engine at Scale]]></title>
        <id>https://prestodb.io/blog/2019/08/05/presto-unlimited-mpp-database-at-scale.html</id>
        <link href="https://prestodb.io/blog/2019/08/05/presto-unlimited-mpp-database-at-scale.html">
        </link>
        <updated>2019-08-05T06:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Wenlei Xie, Andrii Rosa, Shixuan Fan, Rebecca Schlussel, Tim Meehan</p>
<p>Presto is an open source distributed SQL query engine for running analytic queries against data sources of all sizes ranging from gigabytes to petabytes.</p>
<p>Presto was originally designed for interactive use cases, however, after seeing the merit in having a single interface for both batch and interactive, it is now also used heavily for processing batch workloads [6]. As a concrete example, more than 80% of new warehouse batch workloads at Facebook are developed on Presto. Its flexible “connector” design makes it possible to run queries against heterogeneous data sources — such as joining together Hive and MySQL tables without preloading the data.</p>
<p>However, memory-intensive (many TBs) and long-running (multiple hours) queries have been major pain points for Presto users. It is difficult to reason how much memory queries will use and when it will hit memory limit, and failures in long-running queries cause retries which create landing time variance. To improve user experience and scale MPP Database to large ETL workloads, we started this Presto Unlimited project.</p>
]]></summary>
        <author>
            <name>Wenlei Xie</name>
            <uri>https://www.linkedin.com/in/wenleix/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Complete Table Scan: A Quantitative Assessment]]></title>
        <id>https://prestodb.io/blog/2019/07/23/complete-table-scan.html</id>
        <link href="https://prestodb.io/blog/2019/07/23/complete-table-scan.html">
        </link>
        <updated>2019-07-23T06:00:00Z</updated>
        <summary type="html"><![CDATA[<p>In the previous article we looked at the abstract problem statement and possibilities inherent in scanning tables. In this piece we look at the quantitative upside with Presto. We look at a number of queries and explain the findings.</p>
<p>The initial impulse motivating this work is the observation that table scan is by far the #1 operator in Presto workloads I have seen. This is a little over half of all Presto CPU, with repartitioning a distant second, at around 1/10 of the total. The other half of the motivation is ready opportunity: Presto in its pre-Aria state does almost none of the things that are common in table scan.</p>
]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Memory Management in Presto]]></title>
        <id>https://prestodb.io/blog/2019/07/19/memory-tracking.html</id>
        <link href="https://prestodb.io/blog/2019/07/19/memory-tracking.html">
        </link>
        <updated>2019-07-19T06:00:00Z</updated>
        <summary type="html"><![CDATA[<p>In a multi-tenant system like Presto careful memory management is required to keep the system stable and prevent individual queries from taking over all the resources. However, tracking the memory usage of data structures in an application (Presto) running on the Java Virtual Machine (JVM) requires a significant amount of work. In addition, Presto is a distributed system, which makes the problem more complicated. This post provides an overview of how memory management works in Presto, and provides info about the various memory management related JMX counters/endpoints that can be used for monitoring production clusters.</p>
]]></summary>
        <author>
            <name>Nezih Yigitbasi</name>
            <uri>https://www.linkedin.com/in/nezihyigitbasi/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Everything You Always Wanted To Do in Table Scan]]></title>
        <id>https://prestodb.io/blog/2019/06/29/everything-you-always-wanted-to-do-in-a-table-scan.html</id>
        <link href="https://prestodb.io/blog/2019/06/29/everything-you-always-wanted-to-do-in-a-table-scan.html">
        </link>
        <updated>2019-06-29T06:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Orri Erling, Maria Basmanova, Ying Su, Timothy Meehan, Elon Azoulay</p>
<p>Table scan, on the face of it, sounds trivial and boring. What’s there in just reading a long bunch of records from first to last? Aren’t indexing and other kinds of physical design more interesting?</p>
<p>As data has gotten bigger, the columnar table scan has only gotten more prominent. The columnar scan is a fairly safe baseline operation: The cost of writing data is low, the cost of reading it is predictable.</p>
<p>Another factor that makes the table scan the main operation is the omnipresent denormalization in data warehouse. This only goes further as a result of ubiquitous use of lists and maps and other non-first normal form data.</p>
<p>The aim of this series of articles is to lay out the full theory and practice of table scan with all angles covered. We will see that this is mostly a matter of common sense and systematic application of a few principles: Do not do extra work and do the work that you do always in bulk. Many systems like Google’s BigQuery do some subset of the optimizations outlined here. Doing all of these is however far from universal in the big data world, so there is a point in laying this all out and making a model implementation on top of Presto. We are here talking about the ORC format, but the same things apply equally to Parquet or JSON shredded into columns.</p>
]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Introducing the Presto blog]]></title>
        <id>https://prestodb.io/blog/2019/06/28/introducing-the-presto-blog.html</id>
        <link href="https://prestodb.io/blog/2019/06/28/introducing-the-presto-blog.html">
        </link>
        <updated>2019-06-28T06:00:00Z</updated>
        <summary type="html"><![CDATA[<p>Presto is a key piece of data infrastructure at many companies. The community has many ongoing projects for taking it to new levels of performance and functionality plus unique experience and insight into challenges of scale.</p> <p>We are opening this blog...</p>]]></summary>
        <author>
            <name>Orri Erling</name>
            <uri>https://www.linkedin.com/in/orrierling/</uri>
        </author>
    </entry>
</feed>